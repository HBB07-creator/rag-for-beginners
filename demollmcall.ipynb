{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156c6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97b4d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61570e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760016215.857083 1639991 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Upon the digital horizon, vast and wide,\\nWhere data surged and algorithms spun,\\nA mighty wave, of knowledge deep inside,\\nThe Language Models, had their reign begun.\\nThey spoke in verse, in prose, with wisdom fraught,\\nBut isolated, in their textual lair,\\nNo tools they held, no external knowledge sought,\\nJust words to weave, suspended in the air.\\n\\nThen from the code, a vision did arise,\\nA craftsman\\'s hand, to link and to combine.\\nAnd LangChain bloomed, beneath the coder\\'s skies,\\nTo grant the LLMs a purpose, truly divine.\\nIt spoke of \"Chains,\" where steps in order lay,\\nFrom prompt to model, each a link so strong,\\nA structured journey, lighting up the way,\\nWhere isolated tasks could now belong.\\n\\nThe humble prompt, no longer left alone,\\nBut templated, structured, clear, and bright.\\nWith context fetched, and truths from seeds sown,\\nTo guide the model, with specific light.\\nFor when the knowledge, lay beyond its ken,\\nA \"Retriever\" called, to search the vector store,\\nTo pull the facts, again and yet again,\\nAnd ground the answers, to the very core.\\n\\nBut more than words, did LangChain seek to give,\\nIt gave them purpose, action, and a will.\\nWith \"Agents\" born, empowered now to live,\\nAnd choose the \"Tools,\" with computational skill.\\nA web search here, a calculator there,\\nAn API call, to fetch external might.\\nNo longer was the model in despair,\\nBut could interact, and set the world aright.\\n\\nAnd \"Memory\" flowed, a stream through every chat,\\nRecalling past, to guide the present turn.\\nNo conversation lost, no turning back,\\nBut growing wiser, lessons it would learn.\\nThe \"Output Parsers,\" with a careful hand,\\nTransformed the freeform text to structured form.\\nSo other systems, through the digital land,\\nCould weather any data\\'s coming storm.\\n\\nFrom clever bots that chat and understand,\\nTo agents sifting through the data\\'s tide,\\nA new frontier, across the digital sand,\\nWhere LLMs with purpose now could stride.\\nSo raise a glass, to LangChain\\'s clever name,\\nThe architect of AI\\'s grand design.\\nFor weaving wonders, setting minds aflame,\\nA symphony of code, truly divine!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--969f4535-5653-4610-8b1e-5f9f35e879d0-0', usage_metadata={'input_tokens': 8, 'output_tokens': 2402, 'total_tokens': 2410, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1878}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "llm.invoke(\"Write me a ballad about LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000f9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is **New Delhi**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--039ba391-338b-4aba-a8a2-8bcbc7585c4f-0', usage_metadata={'input_tokens': 8, 'output_tokens': 26, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 17}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460404cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
